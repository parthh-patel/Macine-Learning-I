# Machine Learning I @ Georgia Tech

## [Report 1](https://github.com/parthh-patel/Macine-Learning-I/blob/main/Report%201%20-%20K-Means%20and%20Spectral%20Clustering%20Algorithms.pdf)
- Building blocks of a fundamental algorithm: K-Means Clustering (unsupervised learning)
- Derivations of the optimizing function in K-Means
- Image compression using K-Means, built from scratch without any packages (includes images of original vs compressed images w/ # of iterations and run time)
- Evaluation of K-Means clusters and algorithm results
- Spectral clustering (based on the geometry or connectivity of data) 

## [Report 2](https://github.com/parthh-patel/Macine-Learning-I/blob/main/Report%202%20-%20PCA%2C%20Kernel%20Density%20Estimation%2C%20and%20Facial%20Recognition.pdf)
- Linear dimensionality reduction technique known as PCA
- Derivations and math behind the PCA algorithm
- PCA algorithm, built from scratch without any packages, on an example problem of food consumptions in European countries
- PCA algorithm on a dataset of faces using the ISOMAP technique to group images together based on the composition of images
- Density estimation which captures the distributional information of the data (plots of 2D and 3D histograms, KDE plots, heat maps, contour plots, etc.)
- Applying kernel density estimation on a psychological experiment that tested the relationship between different volumes of the brain and political orientation
- Facial recognition by training a PCA algorithm with images of two different subjects and evaluating results using test images and projection residual scores

## [Report 3]()